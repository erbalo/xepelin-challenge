# Xepelin challennge

## A little beginning ##

>If at first you don't succeed, call it version 1.0 __~ Erick Barrera__

### Autor
* Erick Barrera - **ebarreral.isc@gmail.com**

## Contenido

* [Stack tecnol칩gico](#stack-tecnol칩gico)
* [Requisitos](#requisitos)
* [Arquitectura propuesta](#arquitectura-propuesta)
* [Como correr la aplicaci칩n](#como-correr-la-aplicaci칩n)
    - [Esto puede ser de gran ayuda](#esto-puede-ser-de-gran-ayuda)
	- [Importante, leer esta secci칩n](#importante-leer-esta-secci칩n)
* [Consideraciones](#consideraciones)
    - [Make clean](#make-clean)
    - [Obtener top de negocios](#obtener-top-de-negocios)
    - [Obtener ingresos y egresos](#obtener-ingresos-y-egresos)
    - [Procesar archivo](#procesar-archivo)
* [Mejoras](#mejoras)

## Stack tecnol칩gico

- Node
- Typescript
- Express
- Docker
- DynamoDB
- RabbitMQ
- PostgreSQL

## Requisitos

- Sistema operativo basado en UNIX
- Docker
- AWS CLI

## Arquitectura propuesta

![Architecture](xepelin-challenge.jpg)

## Como correr la aplicaci칩n

Para su facilidad se ha colocado un *Makefile* en la ra칤z del proyecto

Lo 칰nico que tiene que correr es:

```
$ make run
```

### Esto puede ser de gran ayuda

Debido a que el archivo a procesar es demasiado grande y tardar칤a apr칩ximadamente 2~3 horas con la configuraci칩n propuesta, he colocado en la ra칤z de este proyecto el backup del volumen de datos tanto para DynamoDB y PostgreSQL

Si lo de sea usar, es __muy importante__ que ejecute el siguiente comando antes de ejecutar el comando `make run`

```shell
$ make pre-context
$ make run
```

Si por error, inicio ya la aplicaci칩n es posible, ejecutando el siguiente flujo:

```shell
$ make down-all
$ make pre-context
$ make run
```

### Importante, leer esta secci칩n

游녤游낗 游녤游낗 游녤游낗 游녤游낗 游녤游낗 游녤游낗 游녤游낗 __README pls!!!__ 游녣游낗 游녣游낗 游녣游낗 游녣游낗 游녣游낗 游녣游낗 游녣游낗

Ya que no cuento con los fondos para colocar un servicio de archivos y no me d칤 el tiempo de crear uno. Se ha implementado
un volumen interno dentro de los contenedores, lo s칠, no es la mejor pr치ctica pero para el uso del ejercicio funciona.

La aplicaci칩n ya est치 configurada para leer el volumne `input` desde la ra칤z de este proyecto.

Por lo que si lo que se desea es subir un archivo, basta con colocarlo en ese folder. La imagen docker fue construida fue
construida para leer ese punto de acceso.

```shell
/Users/mago-macabro$ git clone ....xepelin-challenge
/Users/mago-macabro$ cd xepelin-challenge
/Users/mago-macabro/xepelin-challenge$ cp ./mis-carpetas-macabras/archivo-a-copiar input/otro-archivito.csv
```

---
Cuando inicie con la soluci칩n, se fue transformando en algo m치s complejo pero opt칠 por continuar con lo propuesto, ya que fue
un challenge personal el crear una comunicaci칩n RPC en lugar de REST para los servicios internos.

Hay algo muy importante a notar, hasta que no corr칤 el archivo completo me di cuenta, de que mi computadora muri칩 jajaja y es debido
al dise침o que tiene mejoras pero tambi칠n a que los recursos son locales y compartidos al estar dentro de un contenedor.

Sin lugar a dudas, el mayor punto de dolor de DynamoDB local ya que no tiene le mismo performance y es bastante notorio en la escritura masiva
es por eso que el archivo se dividi칩 en varios archivos para su mejor procesamiento, lo malo es que esto impacta en tiempo, ya que depende
directamente del ordenador donde est칠 se ejecute.


> Es por esa la raz칩n que recomiendo ampliamente reemplazar dentro del archivo docker-compose.yml la variable de entorno CSV_SPLIT_LIMIT a 250
> esto juega un papel con la variable de entorno CHUNK_WORKER_CRON que tendr치 un valor de un minuto, lo que har치 que cada minuto procese 250 operaciones y s칤 el archivo tiene 47K de l칤neas ser치n 188 archivos aprox lo que signfica que ser치n 188 minutos para terminar su lectura

En caso de que la variable CSV_SPLIT_LIMIT tenga un valor mayor a 300, puede que localmente no tenga un buen funcionamiento, ya que localmente esta escriendo sobre un dynamo, un postgres y aparte replicando mediante un broker (RabbitMQ)

## Consideraciones

Puede que tenga otras im치genes corriendo sobre los mismos puertos, en ese caso. Se puede recomendar cerrar los puertos y detener los contenedores. Pero tambi칠n es posibles cambiarlos sobre ambos archivos `docker-compose.yml` y `docker-compose-shared.yml`, esa decisi칩n es bajo su elecci칩n.

Ya que no alcance a colocar un swagger, estos son los posbiles endpoints para utilizar una vez iniciada la aplicaci칩n.


### Make clean

Una vez probado su funcionamiento se puede destruir todo usando:

```
$ make clean
```

Si solo desea reiniciar todo y volver a correr, puede usar el siguiente comando.

```
$ make down-all
$ make run
```

> __Nota__: Lo anterior, incluso reinicia los datos previos guardados en la base de datos.

### Obtener top de negocios

```
GET localhost:8080/api/networks/top?limit=5
```

Donde `limit` es opcional si no se pasa este valor, por default ser치n 5, pero no tiene otras restricciones, incluso se podr칤a poner un n칰mero grande 99999999999.

Response:

```json
{
    "status": 200,
    "data": [
        {
            "business_id": "17",
            "total_relationship": "716"
        },
        {
            "business_id": "2",
            "total_relationship": "474"
        },
        {
            "business_id": "8",
            "total_relationship": "201"
        },
        {
            "business_id": "7",
            "total_relationship": "191"
        },
        {
            "business_id": "78",
            "total_relationship": "176"
        }
    ]
}
```

### Obtener ingresos y egresos

```
GET localhost:8080/api/businesses/:id/summary?from_date=2022-01-01&quantity=2&frequency=MONTHS
```

Donde `id` es el negocio.

Donde `from_date` es la fecha desde donde se calcuar치 con los siguientes par치metros, si no se coloca este valor, por defecto ser치 la fecha actual.

Donde `quantity` ser치 la cardinalidad sumatoria, si no se coloca este valor por defecto es 5.

Donde `frequency` ser치 la cantidad total de d칤as, dentro de sus valores puede ser `DAYS | WEEKS | MONTHS`, si no se coloca este valor por defecto ser치 DAYS

Response:

```json
{
    "status": 200,
    "data": [
        {
            "type": "INCOME",
            "total_amount": "59238562.00"
        },
        {
            "type": "OUTCOME",
            "total_amount": "23974421.00"
        }
    ]
}
```

### Procesar archivo

```
POST localhost:8080/api/invoices/process?file_name=invoices&extension=csv
```

Donde `file_name` es el nombre del archivo que colocar치 en directorio input, mandatorio.

Donde `extension` es la extensi칩n del archivo, mandatorio

Response:

```json
{
    "status": 202,
    "data": {
        "file_name": "invoices",
        "extension": "csv",
        "chunks": 137,
        "path": "/xepelin/app/input/invoices-to-process"
    }
}
```


## Mejoras

Sin lugar tiene mejoras, entre m치s lo iba pensando m치s cosas se me ocurr칤an, definitivamente, el control de archivos es algo que me gustar칤a mejorar, pero ac치
dejo una lista detallada.

- Colocar testing, jajaja puede sonar descabellado, pero en est침a ocasi칩n empece con el dise침o en arquitectura y de responsabilidades que no hay de momento ning칰n test 游뱎
- Implementar una capa de cach칠
- Posiblemente sustituir el dynamo por un mongo (s칩lo para el performance local)
- Colocar estados y dejar un mec치nismo as칤ncrono en la escritura
- Colocar eventos para la distribuci칩n del mismo mensaje, incluso se puede usar la configuraci칩n de RabbitMQ en su formato fanout
- Tambi칠n algo que not칠 fue que al estar todo dentro del mismo proyecto, comparten los recuros del engine de V8 o el event loop, ser칤a bueno que cad치 servicio fuese independiente, de hecho as칤 esta pensado, pero de momento corren sobre el mismo servidor
- Seguridad, de momento los endpoints son p칰blicos, pero no ten칤a scope de momento este rubro
- Swagger, hubiese sido m치s sencillo documentar los endpoints por swagger
- Validaciones, mejorar el sistema de validaciones y coloar i18n para que pueda soportar varios idiomas
- Mejorar por mucho, la sincronizaci칩n de archivos
- En caso de usar Dynamo, hacer un POC sobre la escritura en batch pero de forma local, quiz치 puede reducir la carga de trabajo y de tiempo
- Bit치cora de errores en procesamiento de fallidos
